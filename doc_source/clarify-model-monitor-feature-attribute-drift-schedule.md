# Schedule feature attribute drift monitoring jobs<a name="clarify-model-monitor-feature-attribute-drift-schedule"></a>

Model Explainable monitoring helps you understand and interpret the predictions made by your machine learning models\. When Model Monitor is configured to monitor model explainability, SageMaker automatically detects any drift in relative importance of features and creates reports explaining feature attributions\. 

Call `create_monitoring_schedule()` method to schedule a hourly monitor, to analyze the data with monitoring schedule\. If a baselining job has been submitted, then the monitor automatically picks up analysis configuration from the baselining job\. But if the baselining step is skipped, or the capture dataset has different nature than the training dataset, then analysis configuration has to be provided\. `ModelConfig` is required by `ExplainabilityAnalysisConfig` for the same reason as it is required by the baselining job\. Note that only features are required for computing feature attribution, so ground truth label should be excluded\.
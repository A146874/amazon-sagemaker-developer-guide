# Feature Attributions using Shapley Values<a name="clarify-shapley-values"></a>

SageMaker Clarify provides feature attributions based on the concept of [Shapley value](https://en.wikipedia.org/wiki/Shapley_value) Shapley values from which you can determine the contribution that each feature made to model predictions\. These attributions can be provided for specific predictions and at a global level for the model as a whole\. For example, if an ML model were used for college admissions, the explanations could help determine whether the GPA or the SAT score was the feature most responsible for the model’s predictions and we can determine how responsible they were for an admission decision about a particular student\.

SageMaker Clarify has taken the concept of Shapley values from game theory and deployed it in a machine learning context\. The Shapley value provides a way to quantify the contribution of each player to a game, and hence the means to distribute the total gain generated by a game to its players based on their contributions\. In our machine learning context, we treat the prediction of the model on a given instance as the “game” and the features included in the model as the “players\.” For a first approximation, we may be tempted to determine the marginal contribution or effect of each feature by quantifying the result of either “dropping” that feature from the model or “dropping” all other features from the model\. However, this approach does not take into account that features included in a model are often not independent of each other\. For example, if two features are highly correlated, dropping either feature on its own may not alter the model prediction significantly\. 

To address these potential dependencies, the Shapley value requires that the outcome of each possible combination \(or coalition\) of features must be considered to determine the importance of each feature\. Given d features, there are 2d such possible feature combinations, each corresponding to a potential model\. To determine the attribution for a given feature f, we consider the marginal contribution of including f in all feature combinations \(and associated models\) that do not contain f, and take the average\. It can be shown that Shapley value is the unique way of assigning the contribution or importance of each feature that satisfies certain desirable properties\. In particular, the sum of Shapley values of each feature corresponds to the difference between the predictions of the model and a dummy model with no features\. However, even for reasonable values of d, say 50 features, it is computationally prohibitive and impractical to train 2d possible models\. Hence we need to make use of various approximation techniques\. For this purpose, we have adopted SHapley Additive exPlanations \(SHAP\), which incorporates such approximations and devised a scalable and efficient implementation of the Kernel SHAP algorithm through additional optimizations\. 

For additional information on Shapley values, see [SHAP values explained](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30) and [A Unified Approach to Interpreting Model Predictions](https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)\.
# Measure pre\-training bias<a name="clarify-measure-data-bias"></a>

Measuring bias in ML models is a first step to mitigating bias\. Each measure of bias corresponds to a different notion of fairness\. Even considering simple notions of fairness leads to many different measures applicable in various contexts\. Consider fairness with respect to gender, for example, and, for simplicity, that men and women are the two relevant facets that we refer to as "facets"\. In the case of an ML model for lending, we may want small business loans to be issued to equal numbers of men and women\. Or, when processing job applicants, we may want to see equal numbers of men and women hired\. However, this approach may assume that equal numbers of men and women apply to these jobs, so we may want to condition on the number that apply\. Further, we may want to consider not whether equal numbers apply, but whether we have equal numbers of qualified applicants\. Or, we may consider fairness to be an equal acceptance rate of qualified applicants across gender, or, an equal rejection rate of applicants, or both\. We may use datasets with different proportions of data on the attributes of interest\. This imbalance can conflate the bias measure we pick\. Our models may be more accurate in classifying one facet than in the other\. Thus, we need to choose bias notions and metrics that are valid for the application and the situation\.

We use the following notation to discuss the bias metrics\. The conceptual model described here is for binary classification, where events are labeled as having only two possible outcomes in their sample space, referred to as positive \(with value 1\) and negative \(type 0\)\. But this framework is usually extensible to multi\-category classification in a straightforward way or to cases involving continuous valued outcomes when needed\. In the binary classification case, positive and negative labels are assigned to event outcomes recorded in a raw data set for an advantaged facet *a* and for a disadvantage facet *d*\. These labels y are refereed to as "observed label" to distinguish them from the "predicted" labels y' that are assigned by a machine learning model during the training or inferences stages of the ML lifecycle\. These labels are used to define probability distributions Pa\(y\) and Pd\(y\) for their respective facet outcomes\. 
+ labels: 
  + y represents the n observed labels for event outcomes in a training data set\.
  + y' represents the predicted labels for the n observed labels in the dataset by a trained model\.
+ outcomes:
  + A positive outcome \(with value 1\) for a sample, such as an application acceptance\.
    + n\(1\) is the number of observed labels for positive outcomes \(acceptances\)\.
    + n'\(1\) is the number of predicted labels for positive outcomes \(acceptances\)\.
  + A negative outcome \(with value 0\) for a sample, such as an application rejection\.
    + n\(0\) is the number of observed labels for negative outcomes \(rejections\)\.
    + n'\(0\) is the number of predicted labels for negative outcomes \(rejections\)\.
+ facets:
  + facet *a*: the advantaged group favored by bias
    + na is the number of observed labels for the advantaged facet: na = na\(1\) \+ na\(0\) the sum of the positive and negative observed labels for the advantaged facet\.
    + n'a is the number of predicted labels for the advantaged facet: n'a = n'a\(1\) \+ n'a\(0\) the sum of the positive and negative predicted outcome labels for the advantaged facet\. Note that n'a = na\.
  + facet *d*: the disadvantage group disfavored by bias
    + nd is the number of observed labels for the disadvantaged facet: nd = nd\(1\) \+ nd\(0\) the sum of the positive and negative observed labels for the disadvantaged facet\. 
    + n'd is the number of predicted labels for the disadvantaged facet: n'd = n'd\(1\) \+ n'd\(0\) the sum of the positive and negative predicted labels for the disadvantaged facet\. Note that n'd = nd\.
+ probability distributions for outcomes of the labeled facet data outcomes
  + Pa\(y\) is the probability distribution of the observed labels for the advantaged facet\. For binary labeled data, this distribution is given by the ratio of the number of samples in the advantaged facet labeled with positive outcomes to the total number, Pa\(y1\) = na\(1\)/ na, and the ratio of the number of samples with negative outcomes to the total number, Pa\(y0\) = na\(0\)/ na\. 
  + Pd\(y\) is the probability distribution of the observed labels for the disadvantaged facet\. For binary labeled data, this distribution is given by the number of samples in the disadvantaged advantaged facet labeled with positive outcomes to the total number, Pd\(y1\) = nd\(1\)/ nd, and the ratio of the number of samples with negative outcomes to the total number, Pd\(y0\) = nd\(0\)/ nd\. 

Data collected about people and societies are likely to encode demographic disparities that exist in the world\. Models trained on data biased by these disparities are liable to learn and even exacerbate them\. To identify bias in the data before expending resources to train models on it, we provide data bias metrics that can be computed on the raw dataset before training\. 

All of the pre\-training metrics are model\-agnostic because they do not depend on model outputs and so are valid for any model\. The first bias metric examines facet imbalance, but not outcomes\. It determines the extent to which the amount of training data is representative across different facets, as desired for the application\.  The remaining bias metrics compare the distribution of outcome labels in various ways for the advantaged and disadvantaged facets in the data\. The metrics that range over negative values can detect negative bias\. The following table contains a cheatsheet for quick guidance and links to the pre\-training bias metrics\.


**Table: Pre\-training bias metrics**  

| Bias metric | Description | Example question | Interpreting metric values | 
| --- | --- | --- | --- | 
| [Class imbalance \(CI\)](clarify-bias-metric-class-imbalance.md) | Measures the imbalance in the number of members between advantaged and disadvantaged facets\. |  Could there be gender or racial discrimination due to not having enough data for the disadvantaged facet?   | Normalized range: \[\-1,\+1\]Interpretation:[\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) | 
| [Difference in proportions of labels \(DPL\)](clarify-data-bias-metric-true-label-imbalance.md) | Measures the imbalance of positive outcomes between advantaged and disadvantaged facets\. | Could there be gender or racial discrimination in ML predictions due to prejudicial labeling of the disadvantaged facet in the data? |  Range for normalized binary & multi\-category facet labels: \[\-1,\+1\] Range for continuous labels: \[\-∞, \+∞\] Interpretation: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)  | 
| [Kullback\-Leibler divergence \(KL\)](clarify-data-bias-metric-kl-divergence.md) | Measures how much the outcome distribution of advantaged facet diverges from distribution of the disadvantaged facet, entropically\.  | How different are the distributions for loan application outcomes for gender or racial groups? | Range for binary, multi\-category, continuous: \[0, \+∞\] Interpretation: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) | 
| [Jensen\-Shannon divergence \(JS\)](clarify-data-bias-metric-jensen-shannon-divergence.md)  | Measures how much the outcome distributions of different facets diverge from each other entropically\.  | How different are the distributions for loan application outcomes for gender or racial groups? |  Range for binary, multi\-category, continuous: \[0, \+∞\] Interpretation: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)  | 
| [Lp\-norm \(LP\)](clarify-data-bias-metric-lp-norm.md)  | Measure proportional to the p\-norm difference between the advantaged and disadvantaged distributions of the outcomes in a data set\. | How different are the distributions for loan application outcomes for gender or racial groups? |  Range for binary, multi\-category, continuous: \[0, \+∞\] Interpretation: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)  | 
| [Total variation distance \(TVD\)](clarify-data-bias-metric-total-variation-distance.md)  | Measures half of the L1\-norm difference between the probability distributions for outcomes of the advantaged and disadvantaged facets in a data set | How different are the distributions for loan application outcomes for gender or racial groups? |  Range for binary, multi\-category, and continuous outcomes: \[0, \+∞\]\. [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)  | 
| [Kolmogorov\-Smirnov \(KS\)](clarify-data-bias-metric-kolmogorov-smirnov.md)  | Measures maximum divergence between outcomes in distributions for the advantaged and disadvantaged facets in a data set\. | Which college application outcomes manifest the greatest disparities by gender or racial group? | Range of LP values for binary, multi\-category, and continuous outcomes: \[0,\+1\][\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html) | 
| [Conditional demographic disparity \(CDD\)](clarify-data-bias-metric-cddl.md)  | Measures the disparity of outcomes between the advantaged and disadvantaged facets as a whole, but also by subgroups\. | Do minority groups have a larger proportion of rejections for college admission outcomes than their proportion of acceptances? |  Range of CDD: \(\-1, \+1\) [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html)  | 

For additional information about pre\-training bias metrics, see [A Family of Fairness Measures for Machine Leaning in Finance](https://pages.awscloud.com/rs/112-TZM-766/images/Fairness.Measures.for.Machine.Learning.in.Finance.pdf)\.

**Topics**
+ [Class imbalance \(CI\)](clarify-bias-metric-class-imbalance.md)
+ [Difference in proportions of labels \(DPL\)](clarify-data-bias-metric-true-label-imbalance.md)
+ [Kullback\-Leibler divergence \(KL\)](clarify-data-bias-metric-kl-divergence.md)
+ [Jensen\-Shannon divergence \(JS\)](clarify-data-bias-metric-jensen-shannon-divergence.md)
+ [Lp\-norm \(LP\)](clarify-data-bias-metric-lp-norm.md)
+ [Total variation distance \(TVD\)](clarify-data-bias-metric-total-variation-distance.md)
+ [Kolmogorov\-Smirnov \(KS\)](clarify-data-bias-metric-kolmogorov-smirnov.md)
+ [Conditional demographic disparity \(CDD\)](clarify-data-bias-metric-cddl.md)